{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bca926d4-27bd-4012-9cdd-c4288fc5d4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.62827254 -4.06295992]\n",
      "0.4092958357878465\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Hàm sigmoid dùng để tính xác suất\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Hàm tính xác suất dự đoán dựa trên trọng số w và đầu vào X\n",
    "def prob(w, X):\n",
    "    \"\"\"\n",
    "    X: mảng 2 chiều numpy có kích thước (N, d). N là số lượng điểm dữ liệu, d là số đặc trưng.\n",
    "    w: mảng 1 chiều numpy có kích thước (d) - trọng số của mô hình.\n",
    "    \"\"\"\n",
    "    return sigmoid(X.dot(w))\n",
    "\n",
    "# Hàm tính hàm mất mát (loss) của hồi quy logistic, bao gồm cả regularization\n",
    "def loss(w, X, y, lam):\n",
    "    \"\"\"\n",
    "    X: mảng 2 chiều numpy có kích thước (N, d)\n",
    "    w: mảng 1 chiều numpy có kích thước (d)\n",
    "    y: mảng 1 chiều numpy có kích thước (N), mỗi phần tử là 0 hoặc 1\n",
    "    lam: tham số regularization (số vô hướng)\n",
    "    \"\"\"\n",
    "    z = prob(w, X)  # Tính xác suất dự đoán dựa trên w và X\n",
    "    # Tính giá trị mất mát (cross-entropy) cộng thêm regularization\n",
    "    return -np.mean(y * np.log(z + 1e-8) + (1 - y) * np.log(1 - z + 1e-8)) + 0.5 * lam / X.shape[0] * np.sum(w * w)\n",
    "\n",
    "# Hàm huấn luyện mô hình hồi quy logistic bằng phương pháp gradient descent ngẫu nhiên (SGD)\n",
    "def logistic_regression(w_init, X, y, lam=0.001, lr=0.1, nepoches=2000):\n",
    "    \"\"\"\n",
    "    Hồi quy logistic sử dụng gradient descent ngẫu nhiên.\n",
    "    w_init: vector trọng số khởi tạo ban đầu.\n",
    "    X: các đặc trưng đầu vào.\n",
    "    y: nhãn (0 hoặc 1).\n",
    "    lam: tham số regularization (mặc định là 0.001).\n",
    "    lr: tốc độ học (mặc định là 0.1).\n",
    "    nepoches: số lần lặp (mặc định là 2000).\n",
    "    \"\"\"\n",
    "    N, d = X.shape  # N là số điểm dữ liệu, d là số đặc trưng\n",
    "    w = w_old = w_init  # Khởi tạo trọng số ban đầu\n",
    "    loss_hist = [loss(w_init, X, y, lam)]  # Lưu lịch sử mất mát vào loss_hist\n",
    "    ep = 0  # Biến đếm số lần lặp\n",
    "    while ep < nepoches:  # Vòng lặp cho từng epoch\n",
    "        ep += 1\n",
    "        mix_ids = np.random.permutation(N)  # Trộn ngẫu nhiên thứ tự các điểm dữ liệu\n",
    "        for i in mix_ids:\n",
    "            xi = X[i]  # Lấy điểm dữ liệu thứ i\n",
    "            yi = y[i]  # Lấy nhãn tương ứng của điểm dữ liệu thứ i\n",
    "            zi = sigmoid(xi.dot(w))  # Tính xác suất dự đoán cho điểm dữ liệu này\n",
    "            # Cập nhật trọng số theo SGD\n",
    "            w = w - lr * ((zi - yi) * xi + lam * w)\n",
    "        loss_hist.append(loss(w, X, y, lam))  # Cập nhật lịch sử mất mát\n",
    "        # Kiểm tra điều kiện hội tụ\n",
    "        if np.linalg.norm(w - w_old) / d < 1e-6:\n",
    "            break\n",
    "        w_old = w  # Cập nhật trọng số cũ cho vòng lặp tiếp theo\n",
    "    return w, loss_hist  # Trả về trọng số và lịch sử mất mát\n",
    "\n",
    "# Kiểm tra hồi quy logistic với bộ dữ liệu mẫu\n",
    "X = np.array([[0.50, 0.75, 1.00, 1.25, 1.50, 1.75, 1.75, 2.00, 2.25, 2.50,\n",
    "               2.75, 3.00, 3.25, 3.50, 4.00, 4.25, 4.50, 4.75, 5.00, 5.50]]).T  # Đặc trưng đầu vào (N x 1)\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1])  # Nhãn tương ứng (0 hoặc 1)\n",
    "\n",
    "# Thêm một cột bias vào X để tạo Xbar (X có thêm phần bias)\n",
    "N = X.shape[0]  # Số lượng điểm dữ liệu N\n",
    "Xbar = np.concatenate((X, np.ones((N, 1))), axis=1)  # Kết hợp X với cột bias (toàn 1)\n",
    "\n",
    "# Khởi tạo trọng số ban đầu ngẫu nhiên\n",
    "w_init = np.random.randn(Xbar.shape[1])\n",
    "lam = 0.0001  # Tham số regularization\n",
    "\n",
    "# Huấn luyện mô hình logistic regression\n",
    "w, loss_hist = logistic_regression(w_init, Xbar, y, lam, lr=0.05, nepoches=500)\n",
    "\n",
    "# In ra trọng số cuối cùng và giá trị mất mát cuối cùng\n",
    "print(w)\n",
    "print(loss(w, Xbar, y, lam))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6710fb17-8abe-4f8b-98bb-c5bc61931181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
